{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5BVe5t2zY8ft"
      ],
      "toc_visible": true,
      "mount_file_id": "1nXFCv6HEJTrx-9N1cM6lZIKOb3iCHNzv",
      "authorship_tag": "ABX9TyPVoXAA8SA05yUOfor2CU/i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalgorul/classification-of-musical-genres/blob/main/FMA_MG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "6duJ_mhnhpfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow==2.10.0 pandas==1.5.0 numpy==1.23.3 seaborn==0.12.0 scikit-learn==1.1.2 librosa==0.9.2 imageio==2.22.3\n",
        "!pip install pydub==0.25.1"
      ],
      "metadata": {
        "id": "iO6IR3NBrSPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f7077c3-1eb1-4634-f36a-4400234bf509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub==0.25.1\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import ast\n",
        "import random\n",
        "import shutil\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.callbacks import History\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "from pandas import DataFrame\n",
        "from PIL import ImageFile\n",
        "from keras import models, layers, activations, optimizers, losses, metrics, Sequential, regularizers\n",
        "from keras.layers import Flatten"
      ],
      "metadata": {
        "id": "NRMM58q8gxT7"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global variables"
      ],
      "metadata": {
        "id": "5GEfh3Obhwkb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "k9ACubtEfNcd"
      },
      "outputs": [],
      "source": [
        "metadata_path = \"/content/drive/MyDrive/FMA/dataset/metadata\"\n",
        "\n",
        "genres_path =  \"/content/drive/MyDrive/FMA/dataset/genres\"\n",
        "small_dataset = \"/content/drive/MyDrive/FMA/dataset/fma_small\"\n",
        "images_path = \"/content/drive/MyDrive/FMA/dataset/images\"\n",
        "\n",
        "fma_train_dir = \"/content/drive/MyDrive/FMA/dataset/train\"\n",
        "fma_val_dir = \"/content/drive/MyDrive/FMA/dataset/validation\"\n",
        "fma_test_dir = \"/content/drive/MyDrive/FMA/dataset/test\"\n",
        "\n",
        "directories: Dict[str, str] = {\n",
        "    \"train_dir\": fma_train_dir,\n",
        "    \"val_dir\": fma_val_dir,\n",
        "    \"test_dir\": fma_test_dir,\n",
        "}\n",
        "\n",
        "image_target_size = (288, 432)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "QUXKZUS_iB7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oyq5moN-iH8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aa0e9ae-0f55-4656-fa9b-10fdf2e95242"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "Pg9PI7CH0-Y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "\n",
        "def load_util(filepath: str) -> Optional[DataFrame]:\n",
        "  filename = os.path.basename(filepath)\n",
        "\n",
        "  if 'features' in filename:\n",
        "    return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
        "\n",
        "  if 'echonest' in filename:\n",
        "    return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
        "\n",
        "  if 'genres' in filename:\n",
        "    return pd.read_csv(filepath, index_col=0)\n",
        "\n",
        "  if 'tracks' in filename:\n",
        "    tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n",
        "\n",
        "    COLUMNS = [('track', 'tags'), ('album', 'tags'), ('artist', 'tags'),\n",
        "              ('track', 'genres'), ('track', 'genres_all')]\n",
        "    for column in COLUMNS:\n",
        "      tracks[column] = tracks[column].map(ast.literal_eval)\n",
        "\n",
        "    COLUMNS = [('track', 'date_created'), ('track', 'date_recorded'),\n",
        "              ('album', 'date_created'), ('album', 'date_released'),\n",
        "              ('artist', 'date_created'), ('artist', 'active_year_begin'),\n",
        "              ('artist', 'active_year_end')]\n",
        "    for column in COLUMNS:\n",
        "      tracks[column] = pd.to_datetime(tracks[column])\n",
        "\n",
        "    SUBSETS = ('small', 'medium', 'large')\n",
        "    try:\n",
        "      tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
        "          'category', categories=SUBSETS, ordered=True)\n",
        "    except (ValueError, TypeError):\n",
        "      # the categories and ordered arguments were removed in pandas 0.25\n",
        "      tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
        "          pd.CategoricalDtype(categories=SUBSETS, ordered=True))\n",
        "\n",
        "    COLUMNS = [('track', 'genre_top'), ('track', 'license'),\n",
        "              ('album', 'type'), ('album', 'information'),\n",
        "              ('artist', 'bio')]\n",
        "    for column in COLUMNS:\n",
        "      tracks[column] = tracks[column].astype('category')\n",
        "\n",
        "    return tracks\n",
        "\n",
        "def load() -> DataFrame:\n",
        "  tracks: DataFrame = load_util(f\"{metadata_path}/tracks.csv\")\n",
        "  return tracks\n",
        "\n",
        "\n",
        "def subset(tracks: DataFrame, subset_name: str) -> DataFrame:\n",
        "  assert subset_name in [\"small\", \"medium\"]\n",
        "\n",
        "  subset = tracks.index[tracks[\"set\", \"subset\"] <= \"small\"]\n",
        "  assert subset.isin(tracks.index).all()\n",
        "\n",
        "  return tracks.loc[subset]\n",
        "\n",
        "\n",
        "def list_specific_genre_tracks(tracks: DataFrame, genre: str) -> None:\n",
        "  tracks_with_genre_top = tracks.index[tracks[\"track\", \"genre_top\"] == genre]\n",
        "  print(genre.upper())\n",
        "  print(tracks_with_genre_top.to_list())\n",
        "\n",
        "\n",
        "def get_track_ids_for_genre(tracks: DataFrame, genres: List[str]) -> Dict[str, List[Any]]:\n",
        "  return {\n",
        "      genre: tracks.index[tracks[\"track\", \"genre_top\"] == genre].to_list() for genre in genres\n",
        "  }\n",
        "\n",
        "\n",
        "def genres_top_track_ids(tracks: DataFrame) -> Dict[str, List[Any]]:\n",
        "  subset_small = subset(tracks, \"small\")\n",
        "  genres_top = list(tracks[\"track\", \"genre_top\"].unique())\n",
        "  return get_track_ids_for_genre(subset_small, genres_top)\n",
        "\n",
        "\n",
        "def get_genres_top(tracks: DataFrame) -> List[str]:\n",
        "  genres_top_fixed: List[str] = []\n",
        "  try:\n",
        "    genres_top = list(tracks[\"track\", \"genre_top\"].unique())\n",
        "    for genre in genres_top:\n",
        "      if \" \" not in str(genre):\n",
        "        genres_top_fixed.append(genre)\n",
        "      else:\n",
        "        genres_top_fixed.append(genre.split(\" \")[0])\n",
        "    print(\"Top genres got\")\n",
        "  except Exception as e:\n",
        "    print(f\"Failed to get top genres, error={e}\")\n",
        "  return genres_top_fixed\n",
        "\n",
        "def copy_files(file_paths: List[str], dest_dir: str) -> int:\n",
        "  count = 0\n",
        "  try:\n",
        "    for file in file_paths:\n",
        "      shutil.copy(\n",
        "        file,\n",
        "        os.path.join(\n",
        "          os.path.join(dest_dir),\n",
        "          os.path.split(file)[1],\n",
        "        ),\n",
        "      )\n",
        "      count += 1\n",
        "  except KeyError as e:\n",
        "      print(f\"Failed to copy files to destination directory, error={e}\")\n",
        "  return count\n",
        "\n",
        "\n",
        "def create_directories(directories: List[str]) -> None:\n",
        "  # Create folders\n",
        "  for path in directories:\n",
        "    if os.path.exists(path):\n",
        "      shutil.rmtree(path)\n",
        "      os.mkdir(path)\n",
        "    else:\n",
        "      os.mkdir(path)\n",
        "\n",
        "\n",
        "\n",
        "def create_directory(path: str) -> None:\n",
        "  # Create folder\n",
        "  if os.path.exists(path):\n",
        "    shutil.rmtree(path)\n",
        "    os.mkdir(path)\n",
        "  else:\n",
        "    os.mkdir(path)\n",
        "\n",
        "\n",
        "def remove_directories(directories: Dict[str, str]) -> None:\n",
        "  # Remove folders\n",
        "  for folder_name, path in directories.items():\n",
        "    if os.path.exists(path):\n",
        "      shutil.rmtree(path)\n",
        "\n",
        "\n",
        "def delete_dir_if_empty(self, dir_names: List[str]) -> None:\n",
        "  dirs_to_remove = []\n",
        "  count = 0\n",
        "  for dir_name in dir_names:\n",
        "    songs = glob.glob(\n",
        "      os.path.join(self.genres_path, f\"{dir_name}\", \"*.mp3\"), recursive=True\n",
        "    )\n",
        "    if len(songs) == 0:\n",
        "      dirs_to_remove.append(f\"{self.genres_path}/{dir_name}\")\n",
        "\n",
        "  print(\"Found empty directories:\", len(dirs_to_remove))\n",
        "  print(\"Removing found empty directories...\")\n",
        "  for path in dirs_to_remove:\n",
        "    try:\n",
        "      if os.path.exists(path):\n",
        "        shutil.rmtree(path)\n",
        "        count += 1\n",
        "    except Exception as e:\n",
        "      print(f\"Failed to remove dir, dir={path}, error={e}\")\n",
        "  print(\"Removed empty directories:\", count)"
      ],
      "metadata": {
        "id": "5tdpWaIK6Sfn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialization"
      ],
      "metadata": {
        "id": "Q-Ai3gR935gL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fill_directories_with_songs() -> None:\n",
        "  tracks = load()\n",
        "  ids = genres_top_track_ids(tracks)\n",
        "  all_dirs = os.listdir(small_dataset)\n",
        "\n",
        "  print(\"Getting Top genres...\")\n",
        "  genres_top = get_genres_top(tracks)\n",
        "  print(genres_top)\n",
        "\n",
        "  print(\"Creating directories...\")\n",
        "  try:\n",
        "    genres_dir_paths = [f\"{genres_path}/{genre}\" for genre in genres_top]\n",
        "    create_directories(genres_dir_paths)\n",
        "    print(\"Directories created\")\n",
        "  except Exception as e:\n",
        "    print(f\"Failed to create directories, error={e}\")\n",
        "    raise e\n",
        "\n",
        "  print(\"Getting files to copy...\")\n",
        "  files_to_copy: Dict[str, List[str]] = {}\n",
        "  try:\n",
        "    files_to_copy = {f\"{genres_path}/{genre}\": [] for genre in genres_top}\n",
        "    for dir_name in all_dirs:\n",
        "      for song_file in glob.glob(\n",
        "        os.path.join(small_dataset, f\"{dir_name}\", \"*.mp3\"), recursive=True\n",
        "      ):\n",
        "        song_index = int(song_file.split(\"/\")[-1].split(\".\")[0])\n",
        "        for genre, ids_list in ids.items():\n",
        "          if \" \" in str(genre):\n",
        "            genre = genre.split(\" \")[0]\n",
        "          if song_index in ids_list:\n",
        "            files_to_copy[f\"{genres_path}/{genre}\"].append(song_file)\n",
        "    print(\"Files to copy got\")\n",
        "  except Exception as e:\n",
        "    print(f\"Failed to get files to copy, error={e}\")\n",
        "    raise e\n",
        "\n",
        "  print(\"Copying files to desired directories...\")\n",
        "  try:\n",
        "    files_copied = 0\n",
        "    for genre_dir, songs in files_to_copy.items():\n",
        "      print(\"\\tCurrent genre:\", genre_dir.split(\"/\")[-1])\n",
        "      files_copied += copy_files(file_paths=songs, dest_dir=genre_dir)\n",
        "    if files_copied == 0:\n",
        "      raise ValueError(\"Zero files were copied\")\n",
        "    print(\"Files copied...\")\n",
        "  except Exception as e:\n",
        "    print(f\"Failed to get files to copy, error={e}\")\n",
        "    raise e\n",
        "\n",
        "  delete_dir_if_empty(os.listdir(genres_path))\n",
        "\n",
        "def make_spectograms(genre: str, last_song: int = 0) -> None:\n",
        "  j = 0\n",
        "  songs_path = genres_path\n",
        "  for g in songs_path:\n",
        "    for filename in os.listdir(os.path.join(songs_path, f\"{g}\")):\n",
        "      j = j + 1\n",
        "      if j > last_song:\n",
        "        print(f\"Current file in {g}: {j}\")\n",
        "\n",
        "        song = os.path.join(f\"{songs_path}/{g}\", f\"{filename}\")\n",
        "\n",
        "        y, sr = librosa.load(song)\n",
        "        # print(sr)\n",
        "        mels = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "        figure(figsize=(4, 2))\n",
        "        plt.imshow(librosa.power_to_db(mels, ref=np.max), aspect=\"auto\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        genre_dir_path = f\"{images_path}/{g}\"\n",
        "        if not os.path.exists(genre_dir_path):\n",
        "          os.mkdir(genre_dir_path)\n",
        "\n",
        "        plt.savefig(f\"{genre_dir_path}/{g + str(j)}.png\")\n",
        "        plt.close()\n",
        "\n",
        "def data_init() -> None:\n",
        "  create_directories(list(directories.values()))\n",
        "\n",
        "  genres = list(os.listdir(images_path))\n",
        "  for genre in genres:\n",
        "    print(f\"Current genre: {genre}\")\n",
        "\n",
        "    # Finding all images & split in train, test, and validation\n",
        "    src_file_paths = []\n",
        "\n",
        "    for file in glob.glob(os.path.join(images_path, f\"{genre}\", \"*.png\"), recursive=True):\n",
        "      src_file_paths.append(file)\n",
        "\n",
        "    # Randomizing directories content\n",
        "    random.shuffle(src_file_paths)\n",
        "\n",
        "    test_files = src_file_paths[0:50]\n",
        "    val_files = src_file_paths[50:200]\n",
        "    train_files = src_file_paths[200:]\n",
        "\n",
        "    #  make destination folders for train and test images\n",
        "    for folder_name, path in directories.items():\n",
        "      if not os.path.exists(f\"{path}/{genre}\"):\n",
        "        os.mkdir(f\"{path}/{genre}\")\n",
        "\n",
        "    # Coping training and testing images over\n",
        "    copy_files(\n",
        "        file_paths=train_files, dest_dir=f\"{directories['train_dir']}/{genre}/\"\n",
        "    )\n",
        "    copy_files(\n",
        "        file_paths=test_files, dest_dir=f\"{directories['test_dir']}/{genre}/\"\n",
        "    )\n",
        "    copy_files(file_paths=val_files, dest_dir=f\"{directories['val_dir']}/{genre}/\")\n",
        "  return"
      ],
      "metadata": {
        "id": "IIXaOI4e38vt"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fill_directories_with_songs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "BKjRONAHBF3o",
        "outputId": "458b5abf-1558-424d-8ffe-4b1c81649b11"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting Top genres...\n",
            "Top genres got\n",
            "['Hip-Hop', 'Pop', nan, 'Rock', 'Experimental', 'Folk', 'Jazz', 'Electronic', 'Spoken', 'International', 'Soul-RnB', 'Blues', 'Country', 'Classical', 'Old-Time', 'Instrumental', 'Easy']\n",
            "Creating directories...\n",
            "Directories created\n",
            "Getting files to copy...\n",
            "Files to copy got\n",
            "Copying files to desired directories...\n",
            "\tCurrent genre: Hip-Hop\n",
            "\tCurrent genre: Pop\n",
            "\tCurrent genre: nan\n",
            "\tCurrent genre: Rock\n",
            "\tCurrent genre: Experimental\n",
            "\tCurrent genre: Folk\n",
            "\tCurrent genre: Jazz\n",
            "\tCurrent genre: Electronic\n",
            "\tCurrent genre: Spoken\n",
            "\tCurrent genre: International\n",
            "\tCurrent genre: Soul-RnB\n",
            "\tCurrent genre: Blues\n",
            "\tCurrent genre: Country\n",
            "\tCurrent genre: Classical\n",
            "\tCurrent genre: Old-Time\n",
            "\tCurrent genre: Instrumental\n",
            "\tCurrent genre: Easy\n",
            "Failed to get files to copy, error=Zero files were copied\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-89c2cd1ee13f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfill_directories_with_songs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-242e39223217>\u001b[0m in \u001b[0;36mfill_directories_with_songs\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to get files to copy, error={e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0mdelete_dir_if_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenres_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-242e39223217>\u001b[0m in \u001b[0;36mfill_directories_with_songs\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m       \u001b[0mfiles_copied\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcopy_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msongs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenre_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfiles_copied\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Zero files were copied\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Files copied...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Zero files were copied"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity data test"
      ],
      "metadata": {
        "id": "y2BEj82Z1Uf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sanity_data_test() -> None:\n",
        "  print(\n",
        "    \"Genres directories in train data:\",\n",
        "    len(os.listdir(directories[\"train_dir\"])),\n",
        "  )\n",
        "  print(\n",
        "    \"Genres directories in test data:\", len(os.listdir(directories[\"test_dir\"]))\n",
        "  )\n",
        "  print(\n",
        "    \"Genres directories in validation data:\",\n",
        "    len(os.listdir(directories[\"val_dir\"])),\n",
        "  )\n",
        "\n",
        "  print(\"\\nTotal number of images in:\")\n",
        "  for genre in genres:\n",
        "    print()\n",
        "    for folder_name, path in directories.items():\n",
        "      print(\n",
        "        f\"\\t{folder_name} of {genre} songs: \"\n",
        "        + str(len(os.listdir(f\"{directories[folder_name]}/{genre}\"))),\n",
        "      )\n",
        "\n",
        "sanity_data_test()"
      ],
      "metadata": {
        "id": "LigMLMuoZLHN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "03519519-22ff-4f05-99c6-d17e45caa3ec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1c64a1dec015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m       )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0msanity_data_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-1c64a1dec015>\u001b[0m in \u001b[0;36msanity_data_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   print(\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"Genres directories in train data:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_dir\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   )\n\u001b[1;32m      6\u001b[0m   print(\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data generators"
      ],
      "metadata": {
        "id": "cNwO2DiHK2z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir_on_colab_instance = \"/content/bin/data/train\"\n",
        "val_dir_on_colab_instance = \"/content/bin/data/val\"\n",
        "test_dir_on_colab_instance = \"/content/bin/data/test\""
      ],
      "metadata": {
        "id": "eDQ1ZYAyWGqW"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(train_dir_on_colab_instance):\n",
        "  shutil.rmtree(train_dir_on_colab_instance)\n",
        "\n",
        "if os.path.exists(val_dir_on_colab_instance):\n",
        "  shutil.rmtree(val_dir_on_colab_instance)\n",
        "\n",
        "if os.path.exists(test_dir_on_colab_instance):\n",
        "  shutil.rmtree(test_dir_on_colab_instance)\n",
        "\n",
        "shutil.copytree(fma_train_dir, train_dir_on_colab_instance)\n",
        "shutil.copytree(fma_val_dir, val_dir_on_colab_instance)\n",
        "shutil.copytree(fma_val_dir, test_dir_on_colab_instance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "sWFzYBke9FBf",
        "outputId": "bf6229b7-6752-4abd-9ba0-61d6a8a85155"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/bin/data/test'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
        "\n",
        "# BATCH_SIZE = 128\n",
        "BATCH_SIZE = 20\n",
        "\n",
        "\n",
        "\n",
        "def get_train_data_generator() -> DirectoryIterator:\n",
        "  print(\"Creating train data generator\")\n",
        "  train_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "  train_dir = train_dir_on_colab_instance\n",
        "  target_size = image_target_size\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "      train_dir, \n",
        "      target_size=target_size, \n",
        "      batch_size=BATCH_SIZE, \n",
        "      class_mode=\"categorical\", \n",
        "      color_mode=\"rgba\"\n",
        "  )\n",
        "  return train_generator\n",
        "\n",
        "\n",
        "def get_validation_data_generator() -> DirectoryIterator:\n",
        "  print(\"Creating validation data generator\")\n",
        "  validation_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "  validation_dir = val_dir_on_colab_instance\n",
        "  target_size = image_target_size\n",
        "\n",
        "  validation_generator = validation_datagen.flow_from_directory(\n",
        "      validation_dir, \n",
        "      target_size=target_size, \n",
        "      batch_size=BATCH_SIZE, \n",
        "      class_mode=\"categorical\",  \n",
        "      color_mode=\"rgba\"\n",
        "  )\n",
        "  return validation_generator\n",
        "\n",
        "\n",
        "def list_output_of_generators() -> None:\n",
        "  for data_batch, labels_batch in get_train_data_generator():\n",
        "    print(\"Train generator:\")\n",
        "    print(\"\\tData batch shape:\", data_batch.shape)\n",
        "    print(\"\\tLabels batch shape:\", labels_batch.shape)\n",
        "    print()\n",
        "    break\n",
        "\n",
        "  for data_batch, labels_batch in get_validation_data_generator():\n",
        "    print(\"Validation generator:\")\n",
        "    print(\"\\tData batch shape:\", data_batch.shape)\n",
        "    print(\"\\tLabels batch shape:\", labels_batch.shape)\n",
        "    break\n",
        "\n",
        "\n",
        "# list_output_of_generators()"
      ],
      "metadata": {
        "id": "eQJ_48tbK7jH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model (My network)"
      ],
      "metadata": {
        "id": "GVN5WMAx4qna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "\n",
        "def build_model() -> Sequential:\n",
        "  \"\"\"\n",
        "  Function creating keras model\n",
        "  :return: a model\n",
        "  \"\"\"\n",
        "\n",
        "  input_shape = (*image_target_size, 4)\n",
        "  \n",
        "  model = models.Sequential()\n",
        "  \n",
        "  model.add(layers.Conv2D(8, (3, 3), activation=activations.relu, input_shape=input_shape))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(16, (3, 3), activation=activations.relu))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation=activations.relu))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation=activations.relu))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation=activations.relu))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  # flattening the data to be passed to a dense layer\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(layers.Dense(256, activation=activations.relu))\n",
        "  model.add(layers.Dense(8, activation=activations.softmax))\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=optimizers.RMSprop(learning_rate=0.0005),\n",
        "      loss=losses.categorical_crossentropy,\n",
        "      metrics=[metrics.categorical_accuracy],\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "aBDzG_W9dg3X"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting functions"
      ],
      "metadata": {
        "id": "tQoNzS0JWlAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_training_and_validation_loss(\n",
        "    epochs: range, loss_values: List[float], val_loss_values: List[float]\n",
        ") -> None:\n",
        "  plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "  plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "  plt.title(\"Training and validation loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def show_training_and_validation_accuracy(\n",
        "    epochs: range, acc: List[float], val_acc: List[float]\n",
        ") -> None:\n",
        "  plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
        "  plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
        "  plt.title(\"Training and validation accuracy\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "UZrdC4DvWnZq"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "b_i2SBE-VYiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking if CUDA is available"
      ],
      "metadata": {
        "id": "5BVe5t2zY8ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sfCAucLYvVV",
        "outputId": "271ded0c-a7ed-407a-cd7a-bd6ae89deec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "# Standard output is '/device:GPU:0'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "c6pcNpzzY5hw",
        "outputId": "e6e48ff6-27b3-4921-bde3-766f3ca68ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "cXqDfGhbZBP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import History\n",
        "\n",
        "train_data = get_train_data_generator()\n",
        "val_data = get_validation_data_generator()\n",
        "\n",
        "EPOCHS = 30\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "history: History = model.fit(\n",
        "        train_data,\n",
        "        steps_per_epoch=train_data.samples / train_data.batch_size,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=val_data,\n",
        "        validation_steps=val_data.samples / val_data.batch_size,\n",
        "    )\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/GTZAN/models/gztan_provided_spectograms.h5\"\n",
        "try:\n",
        "  model.save(model_path)\n",
        "  print(f\"Model saved at {model_path}\")\n",
        "except Exception as e:\n",
        "  print(f\"Failed to save model, error={e}\")\n",
        "\n",
        "\n",
        "train_loss_values = history.history.get(\"loss\")\n",
        "val_loss_values = history.history.get(\"val_loss\")\n",
        "train_accuracy = history.history.get(\"categorical_accuracy\")\n",
        "val_accuracy = history.history.get(\"val_categorical_accuracy\")\n",
        "num_of_epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "print(f\"categorical_accuracy max: {max(history.history.get('categorical_accuracy'))}\")\n",
        "print(f\"val_categorical_accuracy max: {max(history.history.get('val_categorical_accuracy'))}\")\n",
        "print(f\"loss min: {min(history.history.get('loss'))}\")\n",
        "print(f\"val_loss min: {min(history.history.get('val_loss'))}\")\n",
        "\n",
        "show_training_and_validation_loss(\n",
        "    epochs=num_of_epochs, loss_values=train_loss_values, val_loss_values=val_loss_values\n",
        ")\n",
        "\n",
        "show_training_and_validation_accuracy(\n",
        "    epochs=num_of_epochs, acc=train_accuracy, val_acc=val_accuracy\n",
        ")"
      ],
      "metadata": {
        "id": "33DQjd7OVc7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "hrMGgoqKNUiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make test folder with one class\n",
        "\n",
        "labels = train_data.class_indices\n",
        "genres = dict((v,k) for k,v in labels.items())\n",
        "\n",
        "test_dir = fma_test_dir + \"/images/\" \n",
        "create_directory(test_dir)\n",
        "\n",
        "for genre in genres:\n",
        "  source = fma_test_dir + \"/\" + genre + \"/\"\n",
        "\n",
        "  # code to move the files from sub-folder to main folder.\n",
        "  files = os.listdir(source)\n",
        "  for file in files:\n",
        "    file_name = os.path.join(source, file)\n",
        "    shutil.move(file_name, test_dir)\n",
        "  os.rmdir(source)\n",
        "  print(f\"Files from {genre} moved\")"
      ],
      "metadata": {
        "id": "0dDwco25jKOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = fma_test_dir\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "BATCH_SIZE = 20\n",
        "\n",
        "# shuffle=False in order to preserve the order of filenames and predictions.\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=image_target_size,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode=\"categorical\", \n",
        "        color_mode=\"rgba\",\n",
        "        shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pubkoF2MiTlJ",
        "outputId": "b755342a-b3b6-4b63-dfcb-a7ac3d1cce95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 49 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict from generator (returns probabilities)\n",
        "test_generator.reset()\n",
        "predictions = model.predict(\n",
        "    test_generator, \n",
        "    steps=len(test_generator), \n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMHWCSFIpHM5",
        "outputId": "a16757f2-179d-4e45-f4d2-bf79c6ecc880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 104ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "predicted_class_indices=np.argmax(predictions,axis=1)\n",
        "labels = genres\n",
        "# labels = train_data.class_indices\n",
        "# labels = dict((v,k) for k,v in labels.items())\n",
        "prediction_results = [labels[k] for k in predicted_class_indices]\n",
        "\n",
        "filenames = test_generator.filenames\n",
        "results = pd.DataFrame({\"Filename\": filenames,\n",
        "                      \"Predictions\": prediction_results})\n",
        "print(results)"
      ],
      "metadata": {
        "id": "Nt2L1GiarTwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, cohen_kappa_score\n",
        "import re\n",
        "\n",
        "\n",
        "classes = sorted([\n",
        "    genres.index(re.sub(r'\\d', '', c.replace(\".png\", \"\"))) \n",
        "    for c in os.listdir(test_dir + \"/images/\")\n",
        "])\n",
        "print(classes)\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "print(y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(classes, y_pred))\n",
        "print('Classification Report')\n",
        "target_names = genres\n",
        "print(classification_report(classes, y_pred, target_names=target_names))\n",
        "print(\"Cohen's Kappa: {}\".format(cohen_kappa_score(classes, y_pred)))\n",
        "print(\"Accuracy: \",accuracy_score(classes, y_pred))\n"
      ],
      "metadata": {
        "id": "8x_oELsGNWYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Results \n"
      ],
      "metadata": {
        "id": "QAtW6NnOiYlz"
      }
    }
  ]
}